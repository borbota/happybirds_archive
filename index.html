<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>happybirds</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/scrolling-nav.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">happybirds</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#intro">intro</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#ml">iterations</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#insights_1">insights</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#insights_2">topics</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#insights_3">URLs</a>
            </li>

          </ul>
        </div>
      </div>
    </nav>

        <!-- <header class="bg-primary text-white"> -->
    <header style="background: url('img/sky_image_358.JPG')"
      <div class="container text-center">
        <font color="white"><h1>university project archive</h1></font>
        <font color="white"><p class="lead">–– happybirds team ––</p></font>
      </div>
    </header>

    <section id="intro">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2>Introduction</h2>
            <!-- <p class="lead"> -->
            <p class="lead"; align="justify">This site is the project documentation of the happybirds team for the capstone project for the postgraduate Data science and big data <a href="http://www.ub.edu/datascience/postgraduate/">course </a> of the University of Barcelona. The tasks were to develop a machine learning algorithm for an annotated dataset and to analyze the dataset for insights. Hereby we present what our team did and what technologies we used. The first part discusses the modelling, the later parts the insights we have found analyzing the dataset.</p>
            
            <p align="justify">The problem to be solved for the capstone project is an airline sentiment tweet classification. The teams of the postraduate course received two datasets: one containing tweets in English already classified and a second dataset with tweets in Spanish, which was classified by the students of the postgraduate course on a platform designed for this task.</p>

            <p align="justify">For the solution presented below, we have developed a project in Python that has all the tools needed to run the necessary phases to import, transform, train, validate, test and optimize for a tweet sentiment classification. All codes are available in <a href="https://github.com/jsantalo/happybirds/">this Github repository</a>.</p>

            <p align="justify">Firstly, the sections below cover the in-depth description of the steps taken for the solution of the classification problem in a chronological order, the results obtained, and the next steps that could have been potentially done on the Spanish dataset. Secondly, the insights are presented we have found upon analyzing the dataset. These two main parts are discussed in the following chapters:</p>
            <ul>
              <li>Machine learning project iterations</li>
              <li>Insights of the dataset</li>
              <li>Topic modelling</li>
              <li>Analysis of URLs</li>
            </ul>
            <p>To navigate between these parts use the menu on the top right corner.</p>
          </div>

        </div>
      </div>
    </section>

    <section id="ml" class="bg-light">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2>Project iterations</h2>
            <h4>Code playground and project architecture definition</h4>
            <p align = "justify">We have started the project with experimenting, ie. “playing around” with the dataset in a Jupyter notebook. We have soon realized that using a notebook to store the final solution would be a problem when team members wanted to share they work with each other. We have agreed to start working on a centralized solution that made the code versioning easy.</p>
            <p align="justify">The main reason why we chose the Python project format instead of working on a lengthy Jupyter Notebook was the flexibility such a project has in terms of code sharing. Versioning a Jupyter Notebook can potentially be a bad idea as it stores all the results within. As a consequence, each time a team member re-executes even just one cell locally, Git recognises it as a change and asks to commit it. There is a way to avoid this phenomenon by resetting the notebook output each time a team member pulls or pushes changes. However, this can easily be forgotten causing subsequent chaos. Having a final version as a Python project enables any team member to execute the parts in the way she prefers. Also, it allows team members to experiment if the code is correctly modularized. Finally, each team member has the chance to do this by using her own Jupyter Notebook, iPython or even directly from the developing tool.</p>
            <p align = "justify">Upon designing the project architecture it was a clear objective to have two main parts separating the train and the evaluation/test parts – just like in case of any supervised machine learning project – in order to avoid common errors committed by mixing the two parts. We have also aimed at keeping the code as simple as possible.</p>
            <br />
            <h4>Transformation and first models</h4>
            <p align = "justify">Once the architecture was defined, the next step was the transformation of the tweets’  text. The core transformations and feature engineering done were in order of execution:
              <ul>
              <li>count and remove URLs;</li>
              <li>calculate uppercase ratio;</li>
              <li>convert all tweets to lowercase;</li>
              <li>check if tweet has emoticon and if so, how many;</li>
              <li>determine text length;</li>
              <li>count and remove punctuation;</li>
              <li>tokenize corpus using SnowballStemmer as a lemmatizer; and</li>
              <li>determine hour, day and day of week of the tweet.</li>
            </ul>
            </p>
            <p align = "justify"> The first model was generated using Bag of Words (BoW) with a Naive Bayes classifier. We soon realized that for the BoW we were forced to split the transformation step into two parts, primarily because when building the BoW itself it was necessary to also train it. Thus if we wanted to fully split the transformation and the training part, we were forced to split the transformation in pre-transform and transform.</p>
            <br />
            <h4>Word2Vec and tuning parameters</h4>
            <p align = "justify">After experimenting with some models like Random Forest and Support Vector Machine (SVM), we started exploring other alternatives instead, such as Word2Vec. After some research we found out that Word2Vec is basically a neural network with a couple of layers. The basic idea is that two words are considered similar – and thus they will have similar vector representation – if they have similar neighbours (neighbour of a word understood as the words that surround this word). In that sense, we had the chance to work with a hybrid model with a part of a seemingly neural network and another part with a classical classifier, which could be SVM or Random Forest. Regarding the integration with the architecture defined, Word2Vec had a similar problem as BoW had: it had to be trained before transforming the data. Also Word2Vec required that the data was tokenized and transformed as a vector.
            </p>
            <p align = "justify">The last step we made was the tuning of the hyperparameters of both SVM and Random Forest. For the first one, we have also developed a normalization in order to ensure the model was receiving the correct data during the training. As happened with the BoW and Word2Vec, the normalization had a part that is considered training so we had to split it too to avoid errors. Finally, we have used the GridSearchCV library to tune up the hyperparameters for both SVM and Random Forest. For the SVM, a RBF kernel was used and C (penalty parameter of the error term) and Gamma (Kernel coefficient) were tuned. For Random Forest the maximum depth used and the number of estimators were also tuned.<p/>
            <br />
            <h4>Final project architecture and code description</h4>
            <p align = "justify">The chart below presents the basic structure of the final project architecture from high perspective. The main idea was to separate the different parts of the machine learning pipeline – such as the data load, data transformation, model training, model evaluation, and test check – all translated into four different Python classes. These four classes are discussed below the chart.
            </p>
            <div style="font-size:80%; text-align:center;">
            <img src="img/capstone_project_flow.png" alt="capstone_project_flow" width="700" height="500">
            Final project architecture</div>
            <p></p>
            <p align = "justify">The first class imports the dataset and returns it into a Pandas dataframe. This separation was made serving generalization, as the dataset does not necessarily come from a .csv file, but could come from other source. We opted for this, as first we have received the English tweets dataset, and received the Spanish later during the course – at that point in an unknown format.</p>
            <p align = "justify">As mentioned earlier, given that we had to both train the BoW, the Word2Vec and/or had to normalize, it was necessary to separate the transformation class’s processes in two parts. Firstly, the code transforms the data itself. After that, the user is supposed to train the BoW, Word2Vec or normalizator. Once done, there is a second function to be called in order to transform the data accordingly. The reason behind was that we wanted to ensure that both training and test executes the exact transformations to minimize functional errors. Given that one of our goals was also looking for flexibility, the architecture of the second transformation function allows the user to decide the usage combination of BoW and/or Word2Vec and/or normalization.</p>
            <p align = "justify">The third class does the training for BoW, Word2Vec, normalization, and even optimization. After training, the model is stored in this class.</p>
            <p align = "justify">Finally, the fourth class performs all the calls to the different parts explained above and depending on the parameters of the calls it can optimize the hyperparameters, train, validate, test a model, and/or generate the required output.</p>
            <br />
            <h4>Results</h4>
            <p align = "justify">For the validation test of the model, the configuration used was test_size=20%, validation_size=25%, and n_iterations=10.</p>
            <br />
            <h6 style="font-weight: bold;">Random Forest with Word2Vec</h6>
            <center><img src="img/big_RF_hyperparamether_tune.png" align="middle"></center>
            <div style="font-size:80%; text-align:center;">Random Forest with Word2Vec</div>
            <p></p>
            <p>Best Hyperparams: max_depth = 11; n_estimators = 483. The results obtained with this hyperparameters are:
            <ul>
              <li>Model best train score is: 0.8921381648654376</li>
              <li>Model best validation score is: 0.5381194409148666</li>
              <li>Model test score is: 0.5285895806861499</li>
            </ul>
            </p>
            <br />
            <h6 style="font-weight: bold;">SVM with Word2Vec without normalization</h6>
            <center><img src="img/big_SVM_hyperparamether_tune_v1.png" align="middle"></center>
           <div style="font-size:80%; text-align:center;">SVM validation accuracy without normalization</div>
           <p></p>
            <p>Best Hyperparams: C = 695.1927961775606, gamma = 3.792690190732254e-05. The results obtained with this hyperparameters are:
              <ul>
              <li>Model best train score is: 0.609239245602882</li>
              <li>Model best validation score is: 0.5609911054637865</li>
              <li>Model test score is: 0.5292249047013977</li>
            </ul>
            </p>
            <br />
            <h6 style="font-weight: bold;">SVM with Word2Vec with normalization</h6>
            <center><img src="img/big_SVM_hyperparamether_tune_v1_norm.png" align="middle"></center>
           <div style="font-size:80%; text-align:center;">SVM validation accuracy with normalization</div>
           <p></p>
           <p>Best Hyperparams: C = 1.4384498882876628, gamma = 0.00615848211066026. The results obtained with this hyperparameters are:
              <ul>
              <li>Model best train score is: 0.695910150455605</li>
              <li>Model best validation score is: 0.5508259212198221</li>
              <li>Model test score is: 0.536848792884371</li>
            </ul>
            </p>
            <br />
            <h6 style="font-weight: bold;">SVM with mixed Word2Vec and BoW with normalization</h6>
            <center><img src="img/big_SVM_hyperparamether_tune.png" align="middle"></center>
           <div style="font-size:80%; text-align:center;">SVM mixed with Word2Vec and BoW validation accuracy with normalization</div>
           <p></p>
           <p>Best Hyperparams: C = 1.4384498882876628, gamma = 0.00615848211066026. The results obtained with this hyperparameters are:
              <ul>
              <li>Model best train score is: 0.7690188599279508</li>
              <li>Model best validation score is: 0.5584498094027954</li>
              <li>Model test score is: 0.554002541296061</li>
            </ul>
            </p>
            <br />
            <h4>A few remarks and next steps</h4>
            <p align = "justify">It has to be noted that the three labels in the dataset were disproportionate, which does have an effect on the whole model. Also, our model might have fallen for overfitting. In order to improve the model's results performance, the following steps could be taken:
             <ul>
              <li>Downsample for the most labeled class that unbalance the dataset taking into account the correlation on the rows.</li>
              <li>Do a deep correlation analysis on the columns in order to reduce the number of variables.</li>
              <li>Do a hyperparameter optimization for BoW and Word2Vec.</li>
              <li>Apply deep learning on neural networks.</li>
            </ul>
            </p>

          </div>
        </div>
      </div>
    </section>

    <section id="insights_1">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2>Insights</h2>
            <p class="lead">An ad hoc analysis of an unbalanced dataset, or What was happening with Iberia?</p>
            <p align="justify">The Spanish tweets dataset contains 7867 tweets from October 25, 2017 to January 8, 2018 downloaded using the keywords AirEurope, Aireurope (sic!), Iberia, Norwegianairline, Ryanair, and Spanair. However, the appeareance of the airlines is rather hectic. The table below contains these airlines, and some others, which popped up during the analysis.</p>
            <style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-s6z2{text-align:center}
.tg .tg-spn1{background-color:#f9f9f9;text-align:center}
.tg .tg-hgcj{font-weight:bold;text-align:center}
</style>
<table class="tg" style="undefined;table-layout: fixed; width: 223px" align = "center">
<colgroup>
<col style="width: 111px">
<col style="width: 112px">
</colgroup>
  <tr>
    <th class="tg-hgcj">airline</th>
    <th class="tg-hgcj">number of mentions</th>
  </tr>
  <tr>
    <td class="tg-spn1">Iberia<br></td>
    <td class="tg-spn1">5100</td>
  </tr>
  <tr>
    <td class="tg-s6z2">Ryanair</td>
    <td class="tg-s6z2">1938</td>
  </tr>
  <tr>
    <td class="tg-spn1">Vueling</td>
    <td class="tg-spn1">204</td>
  </tr>
  <tr>
    <td class="tg-s6z2">Spanair<br></td>
    <td class="tg-s6z2">151</td>
  </tr>
  <tr>
    <td class="tg-spn1">AirEuropa</td>
    <td class="tg-spn1">40</td>
  </tr>
  <tr>
    <td class="tg-s6z2">Norwegian</td>
    <td class="tg-s6z2">27</td>
  </tr>
  <tr>
    <td class="tg-spn1">Jetblue</td>
    <td class="tg-spn1">1</td>
  </tr>
</table>
<div style="font-size:80%; text-align:center;">
            Number of mentions of airlines in the dataset</div>
            <p></p>

            <p align = "justify">The tweets' sentiments were annotated by the students of the postgraduate course. The 48.1 percent of the tweets were annotated as negative, 32.5 percent as neutral, and 19.4 percent as positive. The chart below shows the distribution of the number of tweets by each sentiment by day. The day with the highest traffic was December 14, 2017 – most of the tweets published being negative.</p>
            <p><p/>
            <div style="font-size:80%; text-align:center;">
              <img src="img/sentiment_timeline_ES.png" alt="sentiment timeline" width="700" height="300">
            Distribution of sentiments by day</div>
            <p><p/>
            <p align="justify">If we look for the airlines mentioned, we see that it was Iberia, which was mentioned mostly on December 14, 2017. As out of all airlines mostly Iberia and Ryanair were mentioned in the whole dataset, we are focusing on these two airlines.</p>
            <p><p/>
            <img src="img/airlines_by_day_ES_original_colors.png" alt="airline_mentions_by_day" width="700" height="300">
             <div style="font-size:80%; text-align:center;">
            Mentions of airlines by day</div>
            <p><p/>
            <p align="justify">In what context were the airlines mentioned? The table below shows the rank of each word in terms of number of ocurrence by airline. The word "url" are used after having all links replaced by this word. The URLs part of this analysis will discuss potential explanation on the high number of links in the dataset.<p/>
<div style="font-size:80%; text-align:center;">            
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-88nc{font-weight:bold;border-color:inherit;text-align:center}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-uys7{border-color:inherit;text-align:center}
.tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-fqnz{font-weight:bold;font-style:italic;background-color:#efefef;text-align:center;vertical-align:top}
.tg .tg-aj9k{background-color:#f9f9f9;border-color:inherit;text-align:center}
.tg .tg-abip{background-color:#f9f9f9;border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-08c0{background-color:#efefef;text-align:center;vertical-align:top}
.tg .tg-8dke{font-style:italic;background-color:#efefef;text-align:center;vertical-align:top}
.tg .tg-gbz3{background-color:#efefef;font-style:italic;text-align:center;vertical-align:top}
</style>
<table class="tg" style="undefined;table-layout: fixed; width: 614px" align = "center">
<colgroup>
<col style="width: 64px">
<col style="width: 114px">
<col style="width: 103px">
<col style="width: 103px">
<col style="width: 103px">
<col style="width: 127px">
</colgroup>
  <tr>
    <th class="tg-88nc">rank</th>
    <th class="tg-88nc">Iberia</th>
    <th class="tg-7btt">Ryanair</th>
    <th class="tg-7btt">Vueling</th>
    <th class="tg-7btt">Spanair</th>
    <th class="tg-fqnz"><span style="font-weight:bold">in whole dataset</span></th>
  </tr>
  <tr>
    <td class="tg-aj9k">1</td>
    <td class="tg-aj9k">@iberia</td>
    <td class="tg-abip">ryanair</td>
    <td class="tg-abip">url</td>
    <td class="tg-abip">spanair</td>
    <td class="tg-08c0">url</td>
  </tr>
  <tr>
    <td class="tg-uys7">2</td>
    <td class="tg-uys7">url</td>
    <td class="tg-c3ow">url</td>
    <td class="tg-c3ow">@vueling</td>
    <td class="tg-c3ow">url</td>
    <td class="tg-8dke">@iberia</td>
  </tr>
  <tr>
    <td class="tg-aj9k">3</td>
    <td class="tg-aj9k">iberia</td>
    <td class="tg-abip">@ryanair</td>
    <td class="tg-abip">vueling</td>
    <td class="tg-abip">accidente</td>
    <td class="tg-gbz3">iberia</td>
  </tr>
  <tr>
    <td class="tg-uys7">4</td>
    <td class="tg-uys7">vuelo</td>
    <td class="tg-c3ow">pilotos</td>
    <td class="tg-c3ow">@iberia</td>
    <td class="tg-c3ow">españa</td>
    <td class="tg-8dke">ryanair</td>
  </tr>
  <tr>
    <td class="tg-abip">5</td>
    <td class="tg-abip">hola</td>
    <td class="tg-abip">huelga</td>
    <td class="tg-abip">iberia</td>
    <td class="tg-abip">video</td>
    <td class="tg-gbz3">vuelo</td>
  </tr>
  <tr>
    <td class="tg-c3ow">6</td>
    <td class="tg-c3ow">solo</td>
    <td class="tg-c3ow">vuelos</td>
    <td class="tg-c3ow">ryanair</td>
    <td class="tg-c3ow">vuelo</td>
    <td class="tg-8dke">hola</td>
  </tr>
  <tr>
    <td class="tg-abip">7</td>
    <td class="tg-abip">gracias</td>
    <td class="tg-abip">vuelo</td>
    <td class="tg-abip">@ryanair</td>
    <td class="tg-abip">letal</td>
    <td class="tg-gbz3">@ryanair</td>
  </tr>
  <tr>
    <td class="tg-c3ow">8</td>
    <td class="tg-c3ow">mejor</td>
    <td class="tg-c3ow">españa</td>
    <td class="tg-c3ow">compañía</td>
    <td class="tg-c3ow">cadas</td>
    <td class="tg-8dke">madrid</td>
  </tr>
  <tr>
    <td class="tg-abip">9</td>
    <td class="tg-abip">destino</td>
    <td class="tg-abip">avión</td>
    <td class="tg-abip">vuelo</td>
    <td class="tg-abip">barajas</td>
    <td class="tg-gbz3">vuelos</td>
  </tr>
  <tr>
    <td class="tg-c3ow">10</td>
    <td class="tg-c3ow">madrid</td>
    <td class="tg-c3ow">euros</td>
    <td class="tg-c3ow">vuelos</td>
    <td class="tg-c3ow">canal</td>
    <td class="tg-8dke">gracias</td>
  </tr>
</table>
Most frequently used words by airline and in the whole dataset</div>
<p></p>
<p align="justify">Most of the airlines are mentioned using the "@" sign in the tweets suggesting that by using Twitter's organic mention sign people wanted to communicate with the airline companies – except for Spanair, but it is reasonable to expect from a defunct company. The extensive use of "@"s is especially true for Iberia being @iberia the most frequently used word related to Iberia. Nevertheless, all other words at Iberia do not seem to have negative connotation. As for Ryanair, we see that probably a strike was going on (maybe that of pilots?), where flights were cancelled. As for Vueling, practically this company was mentioned related to the other airlines, we can see that both Ryanair and Iberia were mentioned along with Vueling. Spanair appeared as the accident had the anniversary.<p/>
<p></p>
<p align = "justify">Now that we have a broad picture of our dataset, in order to understand exactly what has happened to Iberia, in the next part we take a dive into text analysis using a widely used method: topic modelling.</p>
          </div>
        </div>
      </div>
    </section>

        <section id="insights_2" class="bg-light">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2>Topic modelling</h2>
            <p class="lead">Happy anniversary Iberia</p>
            <p align = "justify">For a greater depth about the tweets, we decided to use a topic modelling algorithm. The analysis was done with a conventional Latent Dirichlet Allocation (LDA) model in order to extract the volume and percentage contribution of each topic to get an idea of how important a topic is. Using the tool of LDA we get the following interactive visualization.</p>
            <div style="font-size:80%; text-align:center;">
            <iframe src="https://borbota.github.io/jatszos/UB/lda.html" width="1200" height="500" frameborder="1" style="margin-left: -200px">
             </iframe> 
            Topic modelling using LDA and LDAvis</div>
            <p></p>
            <p align = "justify">The Coherence score was used to select appropriate number of topics. After several runs it was decided to let it at 20 topics. Some of the topics are a little bit overlapped but the important and different ones appear clearly separated.</p>
            <br />
            <p class="lead"; align="justify">Inferring the topics from keywords</p>
            <p align = "justify">After looking into all the keywords in the above graph the following topic names were deduced. For each tweet, a dominant topic was assigned. Tweets with a topic probability lower than 20 percent were left uncategorized. When doing topic modelling, the topics are usually not 100 percent clean and clear, thus we have left some question marks in the picture below presenting the topics.</p>
            <div style="font-size:80%; text-align:center;">
              <img src="img/inferring_topics.png" alt="topics and names" width="700" height="400">
            Topics and their respective keywords</div>
            <br />
            <p class="lead"; align="justify">Iberia</p>
            <p align = "justify">In the following plot all the topics and the percent of appearances are displayed (please note that the chart was insipred by Christian Rudder's chart in Dataclysm about the word use of OkCupid profiles). The X axis represents Iberia percentage and the Y axis represents the percentage from all the other companies together. Topics below the line are more important in Iberia dataset and topics above the line are more important for the other airlines.</p>
            <div style="font-size:80%; text-align:center;">
              <img src="img/iberia_graph.png" alt="Iberia graph" width="700" height="400">
            Topics of Iberia vs. all other companies</div>
            <p></p>
            <p>The most relevant topics in Iberia are:
              <ul>
              <li>Topic 9 → #HolaDestino campaign;</li>
              <li>Topic 7 → 25 anniversary of IberiaPlus;</li>
              <li>Topic 0 → Iberia is 90 years old.</li>
            </ul>
            For each day every dominant topic is plotted in the graph below showing the timeline analysis of Iberia's most dominant topics.
            </p>
            <div style="font-size:80%; text-align:center;">
              <img src="img/iberia_timeline.png" alt="Iberia graph" width="700" height="400">
            Timeline of Iberia's most dominant topics by day</div>
            <p></p>
            <p></p>
            <p>The chart suggests that:
              <ul>
              <li>The publicity campaign #holaDestino (topic 9) started on November 14 and finished on December 2.</li>
              <li>The publicity campaign of the 25 years of IberiaPlus (topic 7) started on December 11 and finished on December 23. </li>
              <li>On December 14, the most important topic is the 90th anniversary of Iberia (topic 0).</li>
            </ul>
            Thus, in conclusion what happened in December 14 is the anniversary of Iberia. More information about this campagin click <a href="https://www.iberia.com/es/90-aniversario/">here</a>. It can be seen that Iberia invests a lot of time and effort to continuously have active campaigns, good and positive news. 
          </p>
          <br />
          <p class="lead"; align="justify">Ryanair</p>
          <p align = "justify">Similarly, we had a look at the words used related to Ryanair vs. all other companies.</p>
          <div style="font-size:80%; text-align:center;">
            <img src="img/ryanair_graph.png" alt="Iberia graph" width="700" height="400">
            Topics of Ryanair vs. all other companies</div>
            <p></p>
          <p>the most relevant topics in Ryanair are:
            <ul>
              <li>Topic 8 → call strike;</li>
              <li>Topic 12 → cancel strike;</li>
              <li>Topic 16 → trip sales;</li>
              <li>Topic 14 + Topic 13 → new hand luggage policy.</li>
            </ul>
            <p/>
            <div style="font-size:80%; text-align:center;">
            <img src="img/ryanair_timeline.png" alt="Iberia graph" width="700" height="400">
            Timeline of Ryanair's most dominant topics by day</div>
            <p></p>
            <p align = "justify">The timeline analysis indicates the strike call was around December 11 and December 17. The strike was cancelled around December 18 and December 20. See more information <a href = "https://www.telegraph.co.uk/travel/news/ryanair-strike-flight-cancellations-your-rights/">here.</a></p>
            <p align = "justify">From October 25 to October 27 Ryanair delayed to January its new hand luggage policy, see more information <a href = "https://corporate.ryanair.com/news/new-cabin-bag-policy-delayed-until-mid-jan-2018/">here</a>.</p>


          </div>
        </div>
      </div>
    </section>

        <section id="insights_3">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h2>Analysis of URLs</h2>
            <p class="lead">What URLs were the users sharing?</p>
            <p align = "justify">In the dataset of 7867 tweets, there were 5448 URLs. Some of the tweets had not a single URL, but a few had even three:
              <style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-s6z2{text-align:center}
.tg .tg-spn1{background-color:#f9f9f9;text-align:center}
.tg .tg-hgcj{font-weight:bold;text-align:center}
</style>
<table class="tg" style="undefined;table-layout: fixed; width: 263px" align = "center">
<colgroup>
<col style="width: 131px">
<col style="width: 132px">
</colgroup>
  <tr>
    <th class="tg-hgcj">number of URLs</th>
    <th class="tg-hgcj">number of tweets</th>
  </tr>
  <tr>
    <td class="tg-spn1">0</td>
    <td class="tg-spn1">2684</td>
  </tr>
  <tr>
    <td class="tg-s6z2">1</td>
    <td class="tg-s6z2">4745</td>
  </tr>
  <tr>
    <td class="tg-spn1">2</td>
    <td class="tg-spn1">361</td>
  </tr>
  <tr>
    <td class="tg-s6z2">3</td>
    <td class="tg-s6z2">4</td>
  </tr>
</table>
<div style="font-size:80%; text-align:center;">
            Number of URLs in tweets</div>
<p></p>
<p align = "justify">As Twitter by default shortens links, we have used a small script using the <a href="http://docs.Python-requests.org/en/master/">Requests library<a> to unshorten them, so instead of "https://t.co/8c66y40ejv" we would see "https://www.grandesmedios.com/accidente-vuelo-5022-spanair/". As it is higly recommended to trick websites in order not to be rejected from the site, the snippet had a few seconds of sleeping built in.</p>
<p align = "justify">Out of the 5448 links only 34 were still working (or curling was not omitted).  Most of the received long URLs were leading to Twitter posts or pictures, and only a handful lead to a news portal or a company website. A possible explanation for the few received long URLs could be – apart from the obvious that our URL unshortener code is wrong, – that the links lead to Twitter user's profiles, which do not exist any more (recall that most of the dataset is from last year). There is only one domain appearing more than once in the dataset: "hipertextual.com" coming from campaigns indicated by the ending of the link  ("utm_medium=feed&utm_source=feedpress.me&utm_campaign=Feed:+hipertextual").</p>
<p align = "justify">Having a look at those tweets, which had three links in them, it turned out that three out of four were published by the same user: @joselitoba5. (These tweets are respectively: <a href="http://www.twitter.com/anyuser/status/948828000287625216">tweet 1<a>, <a href = "http://www.twitter.com/anyuser/status/948903621713911808">tweet 2<a>, and <a href="http://www.twitter.com/anyuser/status/931488275524710401">tweet 3<a>.) Among the shared links of this user appear the hipertextual.com domain. If we have a look at the content of that site, we see that it is fairly similar to the content published by @joselitoba5.
 <div style="font-size:80%; text-align:center;">
  <img src="img/joselitoba_hipertextual.png" width="700" height="400">
  excerpt from @joselitoba5's Twitter wall and Hipertextual's Sniply stream</div>
<p></p>
<p align = "justify">@joselitoba5 published 48 900 tweets and has 29 followers – it seems that activity does not pay off for this user. Or @joselitoba5 is a bot using popular content to generate traffic on the Hipertextual Sniply site. The next step of the analysis could be to detect bots. As the dataset has the tweet ID, using the "twitter.com/anyuser/status/{tweetid}" formula, we could get back the user name, and based on that using the Twitter API we could download the profile information of our tweets' authors, their number of followers, number of tweets posted and age of profile, and a metric could be created trying to figure out whether a user is a bot or not.<p>
            </p>
            

          </div>
        </div>
      </div>
    </section>

<section id="insights_2" class="bg-light">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        <h2>Outro</h2>
        <p class="lead">comments?</p>
        <p align = "justify">Here we could discuss major assumptions or just simply what we learntf from this for instance praising github or something. What do you think?</p>
      </div>
    </div>
  </div>
</section>


    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">The members of the happybirds team are <a href="https://github.com/borbota">borbota</a>, <a href="https://github.com/jsantalo">jsantalo</a>, <a href="https://github.com/ldescampsvila">ldescampsvila</a>, and <a href="https://github.com/maytepenella">maytepenella</a>.
        </p>
        <p></p>
        <p class="m-0 text-center text-white">Copyright &copy; happybirds 2018</p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom JavaScript for this theme -->
    <script src="js/scrolling-nav.js"></script>

  </body>

</html>
